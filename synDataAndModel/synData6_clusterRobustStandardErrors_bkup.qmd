---
title: "Cluster-robust standard error"
format: html
editor: visual
number-sections: true
number-depth: 3
---

# Introduction

In a recent project (LTN25), I encountered a dataset composed of daily traffic counts at various sites of a borough collected in two waves. The first wave was collected in Nov 2021, and the second wave was collected in Nov 2023. Each wave contains seven consecutive days of traffic counts for all the sites. Between the two waves, the borough implemented three low traffic neighborhood (LTN) schemes, affecting the traffic volume at some of these sites. We applied a difference-in-differences (DiD) approach to analyse this policy and fitted a two-way fixed effects (TWFE) model to the traffic data to estimate the treatment effect on the treated (refer to as treatment effect hereafter for simplicity).

This dataset does not satisfy the assumptions of TWFE model. Particularly, the error terms (residuals) are not independent and identically distributed (i.i.d.). The correlation arises from the repeated measurements of traffic counts at the same sites in a very short period of time. Consider, for example, engineering work was carried out near a site during the first wave. All the daily traffic counts at this site may be suppressed due to the engineering work. Since the model does not account for engineering work, these effects flowed to the error terms resulting in correlated residuals.

In this post, I will explore how this kind repeated measurements affects TWFE model and show the solutions for mitigating the relevant issues.

```{r}
#| echo: false
#| output: false

# Housekeeping
source("https://raw.githubusercontent.com/jeffzifanwu/rProject/main/procedures/beginScript.R")

# load library
library(dplyr)
library(dataHelper)
```

# TWFE

## Data generating process

The general TWFE model is given by:

$$
y_{i,t} 
= \alpha^{base} 
+ \alpha^{site}_{i}
+ \alpha^{time}_{t}
+ D_{i,t} \beta
+ \epsilon_{i,t}
$$

where:

-   $y_{i,t}$ is the outcome variable for individual $i$ at time $t$;
-   $\alpha^{base}$ is the base effect;
-   $\alpha^{site}_{i}$ is the site fixed effect;
-   $\alpha^{time}_{t}$ is the time fixed effect;
-   $D_{i,t}$ is the treatment indicator (1 if site $i$ is treated at time $t$, 0 otherwise);
-   $\beta$ is the treatment effect;
-   $\epsilon_{i,t}$ is the error term, assumed to be i.i.d.normal.

We now specify a data generating process for a panel data composed of 30 sites and 28 time periods. The sites are indexed by $i = 1, \ldots, 30$ and the time periods by $t = 1, \ldots, 28$. The outcome variable $y_{i,t}$ denotes the traffic volume at site $i$ at time $t$. The frist 20 sites are assigned to treatment group and the rest to the control group. The treatment is applied at time $t = 15$ for the treated sites, and the control sites are never treated. So, the treatment indicator $D_{i,t}$ is defined as follows:

$$
D_{i,t} = 
\begin{cases} 
1 & \text{if } i \leq 20 \text{ and } t \geq 15, \\
0 & \text{otherwise}.
\end{cases}
$$

The paramaters are specified as follows:

-   $\alpha^{base} = 100$;
-   $\alpha^{site}_{i} = i$ for $i = 1, \ldots, 30$ (i.e., the site fixed effects are simply the site indices);
-   $\alpha^{time}_{t} = -20$ when $t$ is a multiple of seven (i.e., $t = 7, 14, 21, 28$) and $0$ otherwise;
-   $\beta = 50$

Error term:

$$
\epsilon_{i,t} \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0, 10)
$$

### Simulation

We simulate the data based on the above specifications in R.

```{r}
# Number of sites (clusters) and periods 
nSite   = 30
nPeriod = 28

# Generate Ids
df.tc = genDimIds(
    dimSize = c(nSite, nPeriod)
  , dimName = c("site_id", "period_id")
)

# Generate individual error terms
df.tc$indivdu_err = rnorm(nrow(df.tc), mean = 0, sd = 10)

# Generate site fixed effects
df.siteEffect = data.frame(site_id = 1:nSite) %>%
  # site fiexed effect equal to its site id
  mutate(site_fixed_effect = site_id)

df.tc = df.tc %>%
  left_join(df.siteEffect, by = "site_id")

# Generate period fixed effects
df.tc = df.tc %>%
  group_by(period_id) %>%
  # Period id is a Multiple of 7: -20, otherwise 0
  mutate(period_fixed_effect = ifelse(period_id %% 7 == 0, -20, 0)) %>%
  ungroup()

# Generate base traffic
df.tc$base = 100

# - - - - - - - - - - - - - - - - 
# Generate treatmnent effects
# - - - - - - - - - - - - - - - -

# Label treatment group  
df.tc = df.tc %>%
  # 2/3 are in treatment group, 1/3 in control group
  mutate(treatment_group = if_else(site_id <= 2/3*nSite, TRUE, FALSE))

# Generate post policy indicator
df.tc = df.tc %>%
  # policy implemented after the 14th period
  mutate(post_policy = if_else(period_id > 14, TRUE, FALSE))

# Label treated units: in treatment group and post policy
df.tc = df.tc %>%
  mutate(is_treated = if_else(treatment_group & post_policy, 1, 0))

# Generate treatment effects
df.tc = df.tc %>%
  mutate(treatment_effect = is_treated*(-50))

# - - - - - - - - - - - - - - - -

# Generate outcome
df.tc = df.tc %>%
  mutate(y = base +
           site_fixed_effect +
           period_fixed_effect +
           treatment_effect +
           indivdu_err 
           )

print(df.tc)
```

### Estimation {#sec-estTwfe}

OLS estimation is used to recover the parameters.

```{r}
# estimation
mdl = lm(y ~ 
           as.factor(is_treated) + 
           as.factor(site_id) + 
           as.factor(period_id)
         , data = df.tc)

# results
summary(mdl)
```

OLS recovered the true parameters with reasonably high precision.

We call four diagnostic plots for the estimated model. The aim is not to check if the model satisfies the OLS assumptions. We know that it does because the data was simulated with these assumptions in mind. Instead, we use these plots to illustrate how the diagnostic plots look like when the model is correctly specified.

```{r}
plot(mdl)
```

# TWFE with correlated errors {#sec-twfeCorrelated}

## Data generating process

The general TWFE model is given by:

$$
y_{i,t} 
= \alpha^{base} 
+ \alpha^{site}_{i}
+ \alpha^{time}_{t}
+ D_{i,t} \beta
+ \epsilon^{cluster}_{c}
+ \epsilon^{individ}_{i,t}
$$

where: - $\epsilon^{cluster}_{c}$ is the cluster-level error term, assumed to be i.i.d.normal across clusters; - $\epsilon^{individ}_{i,t}$ is the individual-level error term, assumed to be i.i.d.normal across individuals and time.

We now specify 60 clusters for this dataset. The sample points of each site are assigned to two clusters depending on whether are collected before or after the treatment. The clusters are indexed by $c = 1, \ldots, 60$. The first 30 clusters are assigned to the pre-treatment period and the rest to the post-treatment period.

The error terms are specified as follows:

$$
\begin{align}
& \epsilon^{cluster}_{c} \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0, 10)
\\
& \epsilon^{individ}_{i,t} \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0, 10)
\end{align}
$$

### Simulation

We simulate the data based on the above specifications.

```{r}
# Generate cluster Ids
df.cluster = df.tc %>%
  distinct(site_id, post_policy) %>%
  arrange(site_id, post_policy) %>%
  mutate(cluster_id = row_number()) %>%
  mutate(cluster_err= rnorm(nrow(.), mean = 0, sd = 10))

df.tc = df.tc %>%
  left_join(df.cluster, by = c("site_id", "post_policy"))

# Generate outcome 
df.tc = df.tc %>%
  mutate(y = base +
           site_fixed_effect +
           period_fixed_effect +
           treatment_effect +
           cluster_err +
           indivdu_err 
           )

print(df.tc %>% select(site_id, period_id, cluster_id, cluster_err, y))
```

### Estimation: conventional OLS standard error

We begin with the conventional OLS estimation procedures and inspect the results.

```{r}
# estimation
mdl = lm(y ~ 
           as.factor(is_treated) + 
           as.factor(site_id) + 
           as.factor(period_id)
         , data = df.tc)

# results
summary(mdl)
```

The estimation results immediately show:

1.  The treatment effect is recovered. However, standard error increases compared to the previous dataset (see @sec-estTwfe).
2.  The estimates of site and time fixed effects are not all reliable.
3.  The overall fitness of the model ($R^2$) declines compared to the previous dataset.

In the following section, we will analyse the residuals of the esimated model and illustrate violations of the OLS assumptions.

### Diagnosis

The diagnostic plots for the estimated model are called below.

```{r}
plot(mdl)
```

These plots appear to be ok. This is because the cluster-level errors are immaterial. Below, we repeat the simulation, estimation, and diagnosis procedures for two more datasets with greater standard deviations of the cluster-level error term.

```{r}
# Generate cluster Ids
df.cluster = df.tc %>%
  distinct(site_id, post_policy) %>%
  arrange(site_id, post_policy) %>%
  mutate(cluster_id = row_number()) %>%
  mutate(cluster_err2= rnorm(nrow(.), mean = 0, sd = 30)) %>%
  mutate(cluster_err3= rnorm(nrow(.), mean = 0, sd = 50))

df.tc = df.tc %>%
  left_join(df.cluster, by = c("site_id", "post_policy", "cluster_id"))

# Generate outcome 
df.tc = df.tc %>%
  mutate(y2 = base +
           site_fixed_effect +
           period_fixed_effect +
           treatment_effect +
           cluster_err2 +
           indivdu_err 
           ) %>%
  mutate(y3 = base +
           site_fixed_effect +
           period_fixed_effect +
           treatment_effect +
           cluster_err3 +
           indivdu_err 
           )

print(df.tc %>% select(site_id, period_id, cluster_id
  , cluster_err , y
  , cluster_err2, y2
  , cluster_err3, y3
  ))

# estimate dataset 2
mdl2 = lm(y2 ~ 
           as.factor(is_treated) + 
           as.factor(site_id) + 
           as.factor(period_id)
         , data = df.tc)

# results
summary(mdl2)

# diagnosis
plot(mdl2)

# estimate dataset 3
mdl3 = lm(y3 ~ 
           as.factor(is_treated) + 
           as.factor(site_id) + 
           as.factor(period_id)
         , data = df.tc)

# results
summary(mdl3)

# diagnosis
plot(mdl3)
```

The residual v.s. fitted values plots show clear patterns. Particularly, when the standard deviation of the cluster-level error term is 50, the residual points are clustered. The QQ plots also indicate that the residuals are deviating from the normal distribution. These plots are organised below in a grid for ease of comparison.

```{r}
par(mfrow = c(3, 2), mar = c(2, 2, 2, 2))

plot(mdl, which = 1,
     cex = 0.75,        # Point size
     cex.lab = 0.75,    # Axis labels
     cex.axis = 0.75,   # Tick labels
     cex.main = 0.5    # Title size
)
plot(mdl, which = 2)  # QQ Plot

plot(mdl2, which = 1)
plot(mdl2, which = 2)

plot(mdl3, which = 1)
plot(mdl3, which = 2)
```

We turn our focus to the treatment effect estimates. For ease of comparison, we summarise the estimates and their standard errors in a table.

```{r}
df.result <- data.frame(
  cluster_err_sd     = c(10, 30, 50),
  beta  = c(coef(mdl)[2],  coef(mdl2)[2],  coef(mdl3)[2]),
  std_err = c(
    sqrt(diag(vcov(mdl)))[2],
    sqrt(diag(vcov(mdl2)))[2],
    sqrt(diag(vcov(mdl3)))[2]
  )) %>%
  mutate(
    ci_lb = beta - 1.96 * std_err,
    ci_ub = beta + 1.96 * std_err
  )


print(df.result)
```

The results show that only when the standard deviation of the cluster-level error term is 10, the conventional OLS estimation recovers the treatment effect i.e., the true treatment effect $\beta$ lies within the 95% confidence interval.

### Estimation: cluster robust standard error

We can reuse the estimated models and compute the cluster-robust standard errors. The cluster-robust standard errors are robust to the correlation of the error terms within clusters. We use the `clubsandwich` package in R to compute the cluster-robust standard errors.

```{r}
library(clubSandwich)

# Compute cluster robust variance-covariance matrix
crVarCov  = vcovCR(mdl,  cluster = df.tc$cluster_id, type = "CR2")
crVarCov2 = vcovCR(mdl2, cluster = df.tc$cluster_id, type = "CR2")
crVarCov3 = vcovCR(mdl3, cluster = df.tc$cluster_id, type = "CR2")

# Compute standard error for all coefficients
est = coef_test(mdl, vcov = crVarCov)
est2= coef_test(mdl2, vcov = crVarCov2)
est3= coef_test(mdl3, vcov = crVarCov3)

print(est)
print(est2)
print(est3)
```

We, again, focus on the treatment effect estimates. For ease of comparison, we extend the previous table to include the cluster-robust standard errors and the 95% confidence intervals based on them. The true treatment effect $\beta$ lies within the 95% confidence interval for all three datasets.

```{r}
df.result = df.result %>%
  mutate(cr_std_err = c(est[2,"SE"], est2[2,"SE"], est3[2,"SE"])) %>%
  mutate(cr_ci_lb = beta - 1.96*cr_std_err) %>%
  mutate(cr_ci_ub = beta + 1.96*cr_std_err)

print(df.result)
```

# Conclusion

This post explores how repeated measurements can jepardise TWFE estimation. We show that conventional OLS estimation is not reliable, when the error terms are correlated due to repeated measurements. In our numerical experiments, the estimation only recovered the true treatment effect when the correlation was minor, that is, the standard deviation of the cluster-level error term was small.

The findings of this experiment are fruitful. It reveals the limitation of OLS estimation in the presence of correlated error terms. More importantly, it alerts us that panel data with long time series may not contain as much information as we think. Many data points in these datasets might be repeated measurements, and thus, carry simular information. They barely improve the precision of OLS estimates. In fact, they inflate the standard errors leading to falsely narrow confidence intervals and incorrect conclusions.
